# -*- coding: utf-8 -*-
"""NewMindSosyalMedyaAnalizi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18WOqtsAfBsST-31FKOXdAdu50jX1AWg2
"""

import pandas as pd
from sentence_transformers import SentenceTransformer, util
import torch
import numpy as np
from transformers import pipeline
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import warnings
warnings.filterwarnings("ignore")

topics_df = pd.read_csv("topics.csv")
opinions_df = pd.read_csv("opinions.csv")

# GÃ¶z atalÄ±m:
print("Topics:")
print(topics_df.head())

print("\nOpinions:")

"""## AÅŸama 1 - Anlamsal EÅŸleÅŸtirme

"""

model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')

topic_embeddings = model.encode(topics_df['text'].tolist(), convert_to_tensor=True)
opinion_embeddings = model.encode(opinions_df['text'].tolist(), convert_to_tensor=True)

best_matches = []
for opinion_idx, opinion_embedding in enumerate(opinion_embeddings):
    cosine_scores = util.cos_sim(opinion_embedding, topic_embeddings)
    best_topic_idx = torch.argmax(cosine_scores).item()
    matched_topic_text = topics_df.iloc[best_topic_idx]['text']

    best_matches.append({
        "opinion_text": opinions_df.iloc[opinion_idx]['text'],
        "matched_topic_text": matched_topic_text,
        "similarity_score": cosine_scores[0][best_topic_idx].item()
    })

matches_df = pd.DataFrame(best_matches)
matches_df.head()

"""## AÅŸama 2 - SÄ±nÄ±flandÄ±rma"""

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
labels = ["Claim", "Counterclaim", "Rebuttal", "Evidence"]

sample_texts = matches_df["opinion_text"].tolist()[:10]

classified_opinions = []
for text in sample_texts:
    result = classifier(text, labels)
    top_label = result['labels'][0]
    top_score = result['scores'][0]

    classified_opinions.append({
        "opinion_text": text,
        "predicted_label": top_label,
        "confidence": top_score
    })

classified_df = pd.DataFrame(classified_opinions)
classified_df.head()

classified_opinions = []

# TÃ¼m gÃ¶rÃ¼ÅŸleri al
all_texts = matches_df["opinion_text"].tolist()

# DÃ¶ngÃ¼yle sÄ±nÄ±flandÄ±r
for i, text in enumerate(all_texts):
    result = classifier(text, labels)
    top_label = result['labels'][0]
    top_score = result['scores'][0]

    classified_opinions.append({
        "opinion_text": text,
        "predicted_label": top_label,
        "confidence": top_score
    })

    # Her 20 adÄ±mda bir durum bildir
    if i % 20 == 0:
        print(f"{i}/{len(all_texts)} classified...")

# DataFrameâ€™e dÃ¶k
classified_df = pd.DataFrame(classified_opinions)
classified_df.head()

classified_df.to_csv("classified_opinions.csv", index=False)

from google.colab import files
files.download("classified_opinions.csv")

"""## AÅŸama 3 - Conclusion Ãœretimi"""

tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-large")
model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-large")

summarizer = pipeline("text2text-generation", model=model, tokenizer=tokenizer)

def generate_summary(topic, opinions):
    # Flan-T5, direkt prompt'u gÃ¶revli cÃ¼mleyle sever:
    prompt = f"Summarize social media opinions about this topic: {topic}. Opinions:\n{opinions}"

    output = summarizer(prompt, max_length=100, do_sample=False)
    return output[0]['generated_text']

sample_topic = matches_df.iloc[0]["matched_topic_text"]

relevant = classified_df[classified_df["opinion_text"].isin(
    matches_df[matches_df["matched_topic_text"] == sample_topic]["opinion_text"]
)]

opinions_text = "\n".join([f"{row['predicted_label']}: {row['opinion_text']}" for _, row in relevant.iterrows()])

conclusion = generate_summary(sample_topic, opinions_text)

print("ðŸ“Œ Topic:", sample_topic)
print("ðŸ§¾ Conclusion:", conclusion)

conclusions = []

# Benzersiz topic'leri al
unique_topics = matches_df["matched_topic_text"].unique()

for topic in unique_topics:
    relevant = classified_df[classified_df["opinion_text"].isin(
        matches_df[matches_df["matched_topic_text"] == topic]["opinion_text"]
    )]

    # Limit the number of opinions to avoid OutOfMemoryError
    relevant = relevant.head(10)

    opinions_text = "\n".join([f"{row['predicted_label']}: {row['opinion_text']}" for _, row in relevant.iterrows()])

    # Check if there are any opinions to summarize
    if opinions_text:
        summary = generate_summary(topic, opinions_text)
    else:
        summary = "No opinions found for this topic."


    conclusions.append({
        "topic": topic,
        "conclusion": summary
    })

conclusion_df = pd.DataFrame(conclusions)
conclusion_df.head()

final_opinions_df = pd.merge(classified_df, matches_df, on="opinion_text", how="left")
final_opinions_df = final_opinions_df[["opinion_text", "predicted_label", "matched_topic_text"]]
final_opinions_df.head()

final_opinions_df.to_csv("opinions.csv", index=False)

conclusion_df.to_csv("conclusions.csv", index=False)

